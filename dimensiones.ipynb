{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargamos los archivos limpios dejados anteriormente en xlsx, debemos colocar el tipo de dato de POS_X y POS_Y como object porque Pandas lee nos None como NaN y luego no se pueden cargar en MySQL;\n",
    "\n",
    "df_hechos_ETL = pd.read_excel('Datasets_limpios/df_hechos_ETL.xlsx', dtype={'POS_X': object, 'POS_Y': object})\n",
    "df_victimas_ETL = pd.read_excel('Datasets_limpios/df_victimas_ETL.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 695 entries, 0 to 694\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   ID                     695 non-null    object        \n",
      " 1   N_VICTIMAS             695 non-null    int64         \n",
      " 2   FECHA                  695 non-null    datetime64[ns]\n",
      " 3   AAAA                   695 non-null    int64         \n",
      " 4   MM                     695 non-null    int64         \n",
      " 5   DD                     695 non-null    int64         \n",
      " 6   HORA                   695 non-null    object        \n",
      " 7   HH                     695 non-null    int64         \n",
      " 8   FRANJA_HORARIA         695 non-null    object        \n",
      " 9   LUGAR_DEL_HECHO        695 non-null    object        \n",
      " 10  TIPO_DE_CALLE          695 non-null    object        \n",
      " 11  CALLE                  695 non-null    object        \n",
      " 12  DIRECCION_NORMALIZADA  695 non-null    object        \n",
      " 13  COMUNA                 695 non-null    int64         \n",
      " 14  POS_X                  684 non-null    object        \n",
      " 15  POS_Y                  684 non-null    object        \n",
      " 16  PARTICIPANTES          695 non-null    object        \n",
      " 17  VICTIMA                695 non-null    object        \n",
      " 18  ACUSADO                695 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(6), object(12)\n",
      "memory usage: 103.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_hechos_ETL.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luego de todo el proceso de ETL en los dos archivos principales, comenzaremos por \n",
    "\n",
    "Relación de Tablas Originales 'hechos' y 'victimas' con Tablas de Hechos y Dimensiones\n",
    "1. Tabla de Hechos: 'HechosAccidentes'\n",
    "\n",
    "La tabla de hechos 'HechosAccidentes' se crea principalmente a partir de la tabla original 'df_hechos_ETL'. A continuación se explica cómo asignar las claves foráneas:\n",
    "\n",
    "FechaID: Proviene de la tabla de dimensiones DimTiempo. La información de fecha (AAAA, MM, DD, HORA, HH) se obtiene de la tabla 'df_hechos_ETL'.\n",
    "\n",
    "UbicacionID: Proviene de la tabla de dimensiones DimUbicacion. La información de ubicación (LUGAR_DEL_HECHO, TIPO_DE_CALLE, CALLE, DIRECCION_NORMALIZADA, COMUNA, POS X, POS Y) se obtiene de la tabla 'df_hechos_ETL'.\n",
    "\n",
    "CaracteristicaAccidenteID: Proviene de la tabla de dimensiones DimCaracteristicasAccidente. La información de características del accidente (TIPO_DE_CALLE,  CALLE, DIRECCION_NORMALIZADA) se obtiene de la tabla 'df_hechos_ETL'.\n",
    "\n",
    "2. Tabla de Hechos: 'HechosVictimas'\n",
    "\n",
    "La tabla de hechos 'HechosVictimas' se crea principalmente a partir de la tabla original 'df_victimas_ETL'. A continuación se explica cómo asignar las claves foráneas:\n",
    "\n",
    "\n",
    "FechaID: Proviene de la tabla de dimensiones DimTiempo. La información de fecha (AAAA, MM, DD) se obtiene de la tabla 'df_victimas_ETL'.\n",
    "\n",
    "VictimaID: Proviene de la tabla de dimensiones DimVictima. La información de la víctima (ROL, SEXO, EDAD, FECHA_FALLECIMIENTO) se obtiene de la tabla 'df_victimas_ETL'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detalles para Crear las Tablas de Dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DimTiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas: FECHA, AAAA, MM, DD, HORA, HH (provenientes tanto de Accidentes como de Víctimas).\n",
    "\n",
    "dim_tiempo = df_hechos_ETL[['FECHA', 'AAAA', 'MM', 'DD', 'HORA', 'HH']].drop_duplicates().reset_index(drop=True)\n",
    "dim_tiempo['FechaID'] = dim_tiempo.index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 694 entries, 0 to 693\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   FECHA    694 non-null    datetime64[ns]\n",
      " 1   AAAA     694 non-null    int64         \n",
      " 2   MM       694 non-null    int64         \n",
      " 3   DD       694 non-null    int64         \n",
      " 4   HORA     694 non-null    object        \n",
      " 5   HH       694 non-null    int64         \n",
      " 6   FechaID  694 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 38.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dim_tiempo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. DimUbicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas: LUGAR_DEL_HECHO, TIPO_DE_CALLE, Calle, Altura, Cruce, Dirección Normalizada, COMUNA, XY (CABA), pos x, pos y (provenientes de Accidentes).\n",
    "\n",
    "dim_ubicacion = df_hechos_ETL[['LUGAR_DEL_HECHO', 'TIPO_DE_CALLE', 'CALLE', 'DIRECCION_NORMALIZADA', 'COMUNA','POS_X', 'POS_Y']].drop_duplicates().reset_index(drop=True)\n",
    "dim_ubicacion['UbicacionID'] = dim_ubicacion.index + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. DimCaracteristicasAccidente\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas: TIPO_DE_CALLE, Calle, Altura, Cruce, Dirección Normalizada (provenientes de Accidentes).\n",
    "dim_caracteristicas_accidente = df_hechos_ETL[['TIPO_DE_CALLE', 'CALLE', 'DIRECCION_NORMALIZADA', 'VICTIMA']].drop_duplicates().reset_index(drop=True)\n",
    "dim_caracteristicas_accidente['CaracteristicaAccidenteID'] = dim_caracteristicas_accidente.index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. DimVictima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas: ROL, SEXO, EDAD, FECHA_FALLECIMIENTO (provenientes de Víctimas).\n",
    "dim_victima = df_victimas_ETL[['ROL', 'SEXO', 'EDAD', 'FECHA_FALLECIMIENTO']].drop_duplicates().reset_index(drop=True)\n",
    "dim_victima['VictimaID'] = dim_victima.index + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Tablas de Hechos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. HechosAccidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la tabla de hechos HechosAccidentes, combinando los identificadores generados con la tabla original Accidentes:\n",
    "df_hechos_accidentes = df_hechos_ETL.merge(dim_tiempo[['FECHA', 'FechaID']], on='FECHA', how='left')\n",
    "df_hechos_accidentes = df_hechos_accidentes.merge(dim_ubicacion[['LUGAR_DEL_HECHO', 'UbicacionID']], on='LUGAR_DEL_HECHO', how='left')\n",
    "df_hechos_accidentes = df_hechos_accidentes.merge(dim_caracteristicas_accidente[['TIPO_DE_CALLE', 'CaracteristicaAccidenteID']], on='TIPO_DE_CALLE', how='left')\n",
    "\n",
    "# Generar un identificador único para cada fila\n",
    "df_hechos_accidentes['HechoID'] = df_hechos_accidentes.index + 1\n",
    "\n",
    "# Seleccionar solo las columnas necesarias para la tabla de hechos\n",
    "df_hechos_accidentes = df_hechos_accidentes[['HechoID', 'ID', 'N_VICTIMAS', 'FechaID', 'UbicacionID', 'CaracteristicaAccidenteID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. HechosVictimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combina los identificadores generados con la tabla original Víctimas:\n",
    "df_hechos_victimas = df_victimas_ETL.merge(dim_tiempo[['FECHA', 'FechaID']], on='FECHA', how='left')\n",
    "df_hechos_victimas = df_hechos_victimas.merge(dim_victima[['ROL', 'SEXO', 'EDAD', 'VictimaID']], on=['ROL', 'SEXO', 'EDAD'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que todas las fechas en df_hechos_victimas estén presentes en dim_tiempo\n",
    "\n",
    "#Primero memorizamos el promedio de HH para que no coloque 0 y se deformen los datos:\n",
    "promedio_hh = dim_tiempo['HH'].mean()\n",
    "\n",
    "#Luego, si hay fechas faltantes, se crean nuevas filas en dim_tiempo con los datos faltantes:\n",
    "fechas_faltantes = df_hechos_victimas[~df_hechos_victimas['FechaID'].isin(dim_tiempo['FechaID'])]['FECHA'].drop_duplicates()\n",
    "if not fechas_faltantes.empty:\n",
    "    fechas_faltantes = fechas_faltantes.dt.strftime('%Y-%m-%d')\n",
    "    fechas_nuevas = pd.DataFrame({\n",
    "        'FECHA': fechas_faltantes,\n",
    "        'AAAA': fechas_faltantes.apply(lambda x: x.split('-')[0]),\n",
    "        'MM': fechas_faltantes.apply(lambda x: x.split('-')[1]),\n",
    "        'DD': fechas_faltantes.apply(lambda x: x.split('-')[2]),\n",
    "        'HORA': '00:00:00',\n",
    "        'HH': promedio_hh\n",
    "    })\n",
    "    fechas_nuevas['FechaID'] = range(dim_tiempo['FechaID'].max() + 1, dim_tiempo['FechaID'].max() + 1 + len(fechas_nuevas))\n",
    "    dim_tiempo = pd.concat([dim_tiempo, fechas_nuevas], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que ambas columnas FECHA estén en formato datetime\n",
    "df_hechos_victimas['FECHA'] = pd.to_datetime(df_hechos_victimas['FECHA'])\n",
    "dim_tiempo['FECHA'] = pd.to_datetime(dim_tiempo['FECHA'])\n",
    "\n",
    "# Actualizar df_hechos_victimas con los nuevos FechaID\n",
    "df_hechos_victimas = df_hechos_victimas.merge(dim_tiempo[['FECHA', 'FechaID']], on='FECHA', how='left', suffixes=('', '_new'))\n",
    "df_hechos_victimas['FechaID'] = df_hechos_victimas['FechaID_new']\n",
    "df_hechos_victimas.drop(columns=['FechaID_new'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una nueva ID para la tabla de hechos\n",
    "df_hechos_victimas['HechoVictimaID'] = df_hechos_victimas.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas necesarias para la tabla de hechos\n",
    "df_hechos_victimas = df_hechos_victimas[['HechoVictimaID', 'ID_HECHO', 'FechaID', 'VictimaID']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de la Procedencia de Columnas\n",
    "\n",
    "FechaID: Común tanto para HechosAccidentes como para HechosVictimas, proviene de Accidentes y Víctimas.\n",
    "\n",
    "UbicacionID: Exclusivo para HechosAccidentes, proviene de Accidentes.\n",
    "\n",
    "CaracteristicaAccidenteID: Exclusivo para HechosAccidentes, proviene de Accidentes.\n",
    "\n",
    "VictimaID: Exclusivo para HechosVictimas, proviene de Víctimas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar los DataFrames en archivos CSV para exportarlos a MySQL\n",
    "dim_tiempo.to_csv('Datasets_para_MySQL/dim_tiempo.csv', index=False)\n",
    "dim_ubicacion.to_csv('Datasets_para_MySQL/dim_ubicacion.csv', index=False,float_format='%.8f')\n",
    "dim_caracteristicas_accidente.to_csv('Datasets_para_MySQL/dim_caracteristicas_accidente.csv', index=False)\n",
    "dim_victima.to_csv('Datasets_para_MySQL/dim_victima.csv', index=False)\n",
    "df_hechos_accidentes.to_csv('Datasets_para_MySQL/hechos_accidentes.csv', index=False)\n",
    "df_hechos_victimas.to_csv('Datasets_para_MySQL/hechos_victimas.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
